{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3599cd09-6330-4a7a-be0c-8f770596ab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "results_df = pd.DataFrame(columns=['image_url', 'image_embedding', 'parse_file'])\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "new_df = pd.DataFrame(columns=['image_url', 'image_embedding', 'parse_file'])\n",
    "with open(datafile_name + \"_embeddings.json\", \"w\") as datafile:\n",
    "    for index, row in originaldf.head(50).iterrows():\n",
    "        url = row['image_url']\n",
    "        hash = row['parse_file']\n",
    "        try:\n",
    "            response = requests.get(url, timeout = 5)\n",
    "            content_type = response.headers.get('content-type')\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        \n",
    "            inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True)\n",
    "        \n",
    "            outputs = model(**inputs)\n",
    "            logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "            probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "            embeddings = outputs.image_embeds[0].detach().numpy().tolist()\n",
    "            \n",
    "            new_row = {\n",
    "                'image_url': url,\n",
    "                'image_embedding':embeddings,\n",
    "                'parse_file': hash\n",
    "            }\n",
    "            \n",
    "            datafile.write(json.dumps(new_row) + '\\n')\n",
    "            print(\"Successful dump #\" + str(index + 1) + '\\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping row with URL: {url}\")\n",
    "            print(e)\n",
    "\n",
    "        new_df = new_df.append(new_row, ignore_index=True)\n",
    "        print(\"Successful\" + '\\n')\n",
    "# with open(datafile_name + \"_embeddings.json\", \"rt\") as datafile:\n",
    "#     ldf = pd.read_json(datafile, lines=True)\n",
    "# display(ldf) #uncomment for entire dataset\n",
    "display(new_df)\n",
    "    # results_df = results_df.append(new_row, ignore_index=True)\n",
    "    # results_df.to_json(datafile_name + \"_embeddings.json.gz\", orient='records', compression = 'gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdaba12-4e27-4a58-a23d-d60f9bf4de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block will hold all imports and internal functions\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "def _extractURLFromFile(input_urls):\n",
    "    if isinstance(input_urls, str):  # Check if input_urls is a single file path\n",
    "        input_urls = [input_urls]  # Convert it to a list with a single element\n",
    "\n",
    "    urls = []\n",
    "    for file_path in input_urls:\n",
    "    # Detect file type based on extension\n",
    "        file_extension = file_path.rsplit('.', 1)[-1].lower()\n",
    "\n",
    "        if file_extension == 'json':\n",
    "            with open(input_urls, 'r') as datafile:\n",
    "                data = json.load(datafile)\n",
    "                _extractURLFromJSON(data, urls)\n",
    "    else:\n",
    "        with open(input_urls, 'r') as datafile:\n",
    "            for line in datafile:\n",
    "                url = line.strip()\n",
    "                if url:  # Skip empty lines\n",
    "                    urls.append(url)\n",
    "    return urls\n",
    "\n",
    "def _extractURLFromJSON(data, urls):\n",
    "    if isinstance(data, list):\n",
    "        for item in data:\n",
    "            _extractURLFromJSON(item, urls)\n",
    "    elif isinstance(data, dict):\n",
    "        for value in data.values():\n",
    "            if isinstance(value, str) and value.startswith('http'):\n",
    "                urls.append(value)\n",
    "            elif isinstance(value, (dict, list)):\n",
    "                _extractURLFromJSON(value, urls)\n",
    "\n",
    "def _imageEmbeddings(url_list)\n",
    "    model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")  #Loading pre-trained CLIP model/processor\n",
    "    processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "    url_embeddings_list = []\n",
    "    for url in url_list\n",
    "        try:\n",
    "            response = requests.get(url, timeout = 5)  #For URLs that are unretrievable. 5 secs for slow retrieval\n",
    "            content_type = response.headers.get('content-type')\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            inputs = processor(text=[\"a photo of a cat\", \"a photo of a dog\"], images=image, return_tensors=\"pt\", padding=True) #Inputs for the model; Can't change text inputs or get an exception\n",
    "            outputs = model(**inputs)\n",
    "            logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "            probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "            embeddings = outputs.image_embeds[0].detach().numpy().tolist()\n",
    "            url_embeddings_list.append((url, embeddings))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping URL: {url}\")\n",
    "            print(e)\n",
    "    return url_embeddings_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f9764-e13d-4482-b2d8-aedcd1464558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User-callable function to create image embeddings\n",
    "def createImageEmbeddings(input_urls): # ONLY RETURNS LIST FOR THE TIME BEING \n",
    "    if isinstance(input_urls, str):\n",
    "        # Read the file and process its contents\n",
    "        url_list = _extractURLFromFile(input_urls)\n",
    "        embeddings = _imageEmbeddings(url_list)\n",
    "                             \n",
    "    if isinstance(input_urls, list):\n",
    "        embeddings = []\n",
    "        # Multiple URLs or file names provided\n",
    "        for url in input_urls:\n",
    "            if isinstance(url, str):\n",
    "                # Process a file\n",
    "                url_list = _extractURLFromFile(url)\n",
    "                embeddings.extend(_imageEmbeddings(url_list))\n",
    "            elif isinstance(url, str) and url.startswith('http'):\n",
    "                # Process a URL\n",
    "                embeddings.extend(_imageEmbeddings(url))\n",
    "        return embeddings\n",
    "            else:\n",
    "                raise ValueError(\"Invalid item in the input list. Expected file name (string) or URL (string).\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid input type. Expected list or file name (string).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c5b69b-70b7-42af-91ea-d67f209b1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#User-callable function to generate text embeddings\n",
    "def createTextEmbeddings(inputText)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
